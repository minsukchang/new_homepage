<!DOCTYPE html>

<head>
    <!-- styling-->
    <meta charset="utf-8">
    <title>Minsuk Chang</title>
    <link href='main.css' type='text/css' rel='stylesheet' />
    <link href='https://fonts.googleapis.com/css?family=Noto+Sans|Open+Sans' rel='stylesheet' type='text/css'>
    <link rel="shortcut icon" href="">

    <!-- metadata-->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap Core CSS-->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

    <!-- more/less buttons-->
    <script type="text/javascript">
        $(document).ready(function () {
            $('.readmore').hide()
            $('.lessbutton').hide()
            $('.morebutton').on("click", function (event) {
                $(this).hide();
                $("#" + event.target.id + "_content").show()
                $("#" + event.target.id + "_less").show()
            });

            $('.lessbutton').on("click", function (event) {
                $(this).hide();
                $("#" + event.target.id.split("_")[0] + "_content").hide()
                $("#" + event.target.id.split("_")[0]).show()
            });
        });
    </script>
</head>

<body>
    <div class="container">
        <!-- bio row -->
        <div class="row">
            <div class="col-md-2"> </div>
            <div class="col-md-8 mt-10 ml-10">
                <div class="row">
                    <div class="col-md-4">
                        <span>
                            <img id="profilepic" class="img-responsive rounded-circle mx-auto mb-1" src="img/me2.png"
                                alt="Minsuk's profile picture">
                        </span>
                        <div id=social class="mx-auto">
                            <a href="mailto: minsuk@minsukchang.com"><i class="fas fa-2x fa-envelope"></i></a>
                            <a href="https://scholar.google.co.uk/citations?user=1j2nBpoAAAAJ"><i
                                    class="fas fa-2x fa-graduation-cap"></i></a>
                            <a href="https://github.com/minsukchang"><i class="fab fa-2x fa-github"></i></a>
                            <a href="https://twitter.com/minsuk_chang"><i class="fab fa-2x fa-twitter"></i></a>
                            <a href="https://facebook.com/minsuk.chang"><i class="fab fa-2x fa-facebook-f"></i></a>
                            <a href="https://linkedin.com/in/minsuk"><i class="fab fa-2x fa-linkedin"></i></a>
                        </div>
                    </div>
                    <div class="col-md-8">
                        <div class="myname">Minsuk Chang</div>
                        <p class="intro">I'm a <a href="https://cs.kaist.ac.kr/">Computer Science</a> PhD student in the
                            <a href="https://www.kixlab.org/">KIXLAB</a> at
                            <a href="https://www.kaist.ac.kr">KAIST</a> advised by <a href="https://juhokim.com/">Juho
                                Kim</a>. Here's my <a href="files/CV_minsukchang_2020_USLetter.pdf"> CV (pdf).</a> </p>
                        <p class="intro">
                            I build computational representations of user tasks for the purpose of using them as interface design materials. 
                            Specifically, I'm interested in extracting and understanding the compositionality of user tasks 
                            by applying machine learning and human computation techniques to naturally crowdsourced tutorials and demonstrations.

                            <a class="morebutton" href="research.html"> Read more (seprate page)</a>
                    </div>
                </div>
            </div>
            <div class="col-md-2"> </div>
        </div>
        <!-- bio row END-->

        <!-- news row -->
        <div class="row">
            <div class="col-md-2"> </div>
            <div class="col-md-8">
                <div class="pub">Latest News and Travels</div>
                <span class="date">April 2020 :</span><span class="news"> <a href="https://chi2021.acm.org">CHI2021</a> website is up! Happy to be on the organizing committee!<br>
                <span class="date">April 2020 :</span><span class="news"> <a href="https://openreview.net/forum?id=qXEzq5agzIN">Workflow Graph</a> has been accepted to <a href="https://graphicsinterface.org/conference/2020/">the Graphics Interface conference(GI) 2020</a>! Camera-ready and project website will be updated soon!<br>
                <span class="date">Jan 2020 :</span><span class="news"> Honored and excited to serve as a program committee member for <a href="https://graphicsinterface.org/conference/2020/">the Graphics Interface conference(GI) 2020</a>!<br>
                <span class="date">Dec 11 2019 :</span><span class="news"> Done with the PhD thesis proposal. Thanks to
                    the committee again for the amazing experience!<br>
                    <span class="date">Oct 26-29 2019 :</span><span class="news"> <a
                            href="http://schedule.bid-seminar.com/speakers/171"> Invited Talk </a>at Berkeley Institute
                        of Design - Fall 2019 Seminar Series</span><br>
                    <span class="date">Oct 23-25 2019 :</span><span class="news"> Visiting Harvard University + <a
                            href="https://www.csail.mit.edu/event/data-models-sequential-tasks-user-interface-design">Invited
                            Talk </a>at MIT CSAIL HCI Seminar Series 2019</span><br>
                    <span class="date">Oct 19-23 2019 :</span><span class="news"> UIST 2019, New Orleans, LA</span><br>

                    <span class="morebutton" id="article00"> More News </span>
                    <span class="readmore" id="article00_content">
		<span class="date">September 2019 :</span><span class="news"> Honored and excited to serve as a program committee member for <a href="https://www2020.thewebconf.org/">the web conference(WWW) 2020</a>!<br>
                        <span class="date">August 2019 :</span><span class="news"><i>Data Structures for Designing
                                Interactions with Contextual Task Support</i> has been accepted to UIST 2019 Doctoral
                            Symposium. See you in New Orleans! </span><br>
                        <span class="date">July 2019 :</span><span class="news"> Excited to serve as the <i>Video
                                Chair</i> for <a href="https://iss.acm.org/2019/">ISS 2019</a>! I just love videos.
                        </span><br>
                        <span class="date">June 3 2019 :</span><span class="news"> Started summer internship at
                            MSR+AI!</span><br>
                        <span class="date">May 31 2019 :</span><span class="news"> Invited to give a talk on data-driven
                            techniques for user task modeling @ <a
                                href="https://www.ibs.re.kr/datascience/">IBS</a></span><br>
                        <span class="date">May 30 2019 :</span><span class="news"> Invited as a panel to discuss "how to
                            survive grad school" in <a href="https://nmsl.kaist.ac.kr/courses/i2r">Intro to Research</a>
                            class </span><br>
                        <span class="date">May 28 2019 :</span><span class="news"> Gave a talk on what HCI research is
                            like for ~90 undergrads in <a
                                href="https://www.kixlab.org/courses/cs374-spring-2019/index.html">Intro to HCI</a>
                            class </span><br>
                        <span class="date">May 3-10 2019 :</span><span class="news"> In Glasgow for CHI 2019! Let's
                            meet! </span><br>
                        <span class="date">Apr 2019 :</span><span class="news"> Presented the upcoming <a
                                href="https://minsukchang.com/proj-voicevideo/">CHI paper on looking at Voice UI and
                                Video UI together </a> at <a href="http://event.sigchi.kr/">SIGCHI Korea Local Chapter
                                spring workshop</a> and received outstanding presentation award!</a> The streak is now
                            two years in a row!</span><br>
                        <span class="date">Mar 2019 :</span><span class="news"> My position paper on the two cultures of
                            interface modeling(data-driven and algorithmic) has been accepted to the <a
                                href="https://hcicompmodeling.wordpress.com/">CHI 2019 Computational Modeling in
                                Human-Computer Interaction Workshop.</a></span><br>
                        <span class="date">Feb 2019 :</span><span class="news"> <a
                                href="https://recipescape.kixlab.org">RecipeScape</a> featured in <a
                                href="https://cs.kaist.ac.kr">KAIST School of Computing</a>'s <a
                                href="https://cs.kaist.ac.kr/bbs/research">research highlight</a>!</span><br>
                        <span class="date">Feb 2019 :</span><span class="news"> Our work on subgoal labeling as feedback
                            intervention has been accepted for <a href="https://chi2018.acm.org/">CHI 19
                                LBW!</a></span><br>
                        <span class="date">Jan 2019 :</span><span class="news"> Will be spending the summer at <a
                                href="https://www.microsoft.com/en-us/research/group/information-and-data-sciences/">Microsoft
                                AI + Research </a> @ Redmond. Super excited!</span><br>
                        <span class="date">Dec 2018 :</span><span class="news"> Voice interfaces for video tutorials I
                            worked on during the summer @ <a href="https://research.adobe.com">Adobe Research</a> has
                            been conditionally accepted to <a href="https://chi2019.acm.org/">CHI 2019</a>. See you @
                            Glasgow!</span><br>
                        <span class="date">Nov 2018 :</span><span class="news"> Started winter internship at <a
                                href="https://www.autodeskresearch.com/groups/user-interface">Autodesk Research</a> @
                            Toronto!</span><br>
                        <span class="date">Oct 14-19 2018 :</span><span class="news"> Traveling to <a
                                href="https://uist.acm.org/uist2018/">UIST 18</a> @ Berlin, Germany. SV'ing
                            again!</span> <br>
                        <span class="date">Aug 22 2018 :</span><span class="news"> Visiting <a
                                href="https://www.cs.ubc.ca/nest/imager/hci.php">University of British Columbia </a>to
                            give a talk on voice+video interfaces. </span><br>
                        <span class="date">Jun 2018 :</span><span class="news"> Started research internship at <a
                                href="https://research.adobe.com">Adobe Research</a> @ Seattle! Seattle people, let's
                            meet!. </span><br>
                        <span class="date">Apr 2018 :</span><span class="news"> at <a
                                href="https://chi2018.acm.org/">CHI 2018</a> in Montreal, QC, Canada! Presenting
                            RecipeScape on thursday morning. </span><br>
                        <span class="date">Apr 2018 :</span><span class="news"> Will present RecipeScape at <a
                                href="http://sigchi.kr/">SIGCHI Korea Local Chapter</a> 2018 Spring Academic Workshop
                        </span><br>
                        <span class="date">Mar 2018 :</span><span class="news"> Invited to <a
                                href="https://sensemakingchi2018.com/">CHI 2018 Sensemaking Workshop.</a> </span><br>
                        <span class="date">Mar 2018 :</span><span class="news"> Excited to spend the summer at <a
                                href="https://research.adobe.com">Adobe Research</a> @ Seattle!</span><br>
                        <span class="date">Feb 2018 :</span><span class="news"> Presented a poster on RecipeScape at <a
                                href="https://hci.kaist.ac.kr">HCI@KAIST</a> Winter Workshop. Received best poster
                            award! </span><br>
                        <span class="date">Dec 2017 :</span><span class="news"> Our RecipeScape paper is conditionally
                            accepted to <a href="https://chi2018.acm.org/">CHI 2018</a>! </span><br>
                        <span class="date">Oct 22 - 24, 2017 :</span><span class="news"> Student Volunteering for <a
                                href="https://uist.acm.org/uist2017/">UIST 2017</a> @ Quebec City, QC, Canada
                        </span><br>
                        <span class="date">May 06 - 11, 2017 :</span><span class="news"> Student volunteering for <a
                                href="https://chi2017.acm.org/">CHI 2017</a> @ Denver, CO, USA </span><br>
                        <span class="date"> Feb 2017</span><span class="news"> Our LBW paper on large scale recipe
                            mining as been accepted to <a href="https://chi2017.acm.org/">CHI 2017</a>!</span><br>
                        <span class="date"> Mar 2016</span><span class="news"> Started my journey in HCI research with
                            <a href="https://juhokim.com">Juho!</a></span><br>
                    </span>
                    <span class="lessbutton" id="article00_less"> Less News </span>
            </div>
            <div class="col-md-2"> </div>
        </div>
        <!-- news row end-->


        <!-- pubs row -->
        <div id="fullpaper" class="row">

            <div class="col-md-2"> </div>
            <div class="col-md-8">
                <div class="pub">Conference Papers (Selected)</div>
                <!-- publication template 
                    <div class="eachpub">
                        <div class="meta">
                            <div class="conference"> </div>
                            <div class="title"> </div>
                            <div class="authors"> <b>Minsuk Chang</b> </div>
                        </div>
                        <div class="abstract">
                            
                            <span class="morebutton" id="article2"> Read More </span>
                            <span class="readmore" id="article2_content">
                            
                        
                            </span> 
                            <span class="lessbutton" id="article2_less"> Read Less </span>
                        </div>
                        <div class="links"> <a target="_blank" href=""> website </a>  &middot; <a target="_blank" href=""> pdf </a>
                        </div>
                    </div>
                -->
               
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> GI 2020</div>
                        <div class="title"> Workflow Graphs: A Computational Model of Collective Task Strategies for 3D Design Software </div>
                        <div class="authors">  <span class="authorminsuk">Minsuk Chang</span>, <a
                            href="http://www.benlafreniere.ca/">Ben Lafreniere</a>, <a
                            href="http://juhokim.com">Juho Kim</a>, <a
                            href="https://www.autodeskresearch.com/people/george-fitzmaurice">George Fitzmaurice</a>, <a
                            href="https://www.tovigrossman.com/">Tovi Grossman</a>
                        </div>
                    </div>
                    <div class="abstract">
                        This paper introduces Workflow graphs, or W-graphs, which encode how the approaches taken by multiple users performing a fixed 3D design task converge and diverge from one another. 
                        The graph's nodes represent equivalent intermediate task states across users, and directed edges represent how a user moved between these states, 
                        inferred from screen recording videos, command log data, and task content history. 
                        <span class="morebutton" id="article2"> Read More </span>
                        <span class="readmore" id="article2_content">
                        The result is a data structure that captures alternative methods for performing sub-tasks (e.g., modeling the legs of a chair) and alternative strategies of the overall task. 
                        As a case study, we describe and exemplify a computational pipeline for building W-graphs using screen recordings, 
                        command logs, and 3D model snapshots from an instrumented version of the Tinkercad 3D modeling application, 
                        and present graphs built for two sample tasks. We also illustrate how W-graphs can facilitate novel user interfaces with scenarios in workflow feedback, on-demand task guidance, and instructor dashboards.
                        </span> 
                        <span class="lessbutton" id="article2_less"> Read Less </span>
                    </div>
                    <div class="links"> <a class="btn btn-outline-primary btn-sm disabled"  href=""> website </a>  &middot; <a class="btn btn-outline-primary btn-sm disabled" href=""> pdf </a> &middot; <a class="btn btn-outline-primary btn-sm"  href="https://openreview.net/forum?id=qXEzq5agzIN"> reviews </a>
                    </div>
                </div>
                   
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2019 </div>
                        <div class="title"> How to Design Voice Based Navigation for How-To Videos</div>
                        <div class="authors"> <span class="authorminsuk">Minsuk Chang</span>, <a
                                href="https://scholar.google.ca/citations?user=O3xpA-AAAAAJ">Ahn Truong</a>, <a
                                href="http://www.oliverwang.info">Oliver Wang</a>, <a
                                href="https://graphics.stanford.edu/~maneesh/">Maneesh Agrawala</a>, <a
                                href="http://juhokim.com">Juho Kim</a> </div>
                    </div>
                    <div class="abstract">
                        <!-- what to show first -->
                        When watching how-to videos related to physical tasks, users’ hands are often occupied by the
                        task, making voice input a natural fit.
                        To better understand the design space of voice interactions for how-to video navigation, we
                        conducted three think-aloud studies using:
                        1) a traditional video interface, 2) a research probe providing a voice controlled video
                        interface, and 3) a wizard-of-oz interface.
                        <span class="morebutton" id="article3"> Read More </span>
                        <span class="readmore" id="article3_content">
                            <!-- rest of what to show on "more" -->
                            From the studies, we distill seven navigation objectives and their underlying intents:
                            pace control pause, content alignment pause, video control pause, reference jump, replay
                            jump, skip jump, and peek jump.
                            Our analysis found that users’ navigation objectives and intents affect the choice of
                            referent type and referencing approach in command utterances.
                            Based on our findings, we recommend to 1) support conversational strategies like sequence
                            expansions and command queues,
                            2) allow users to identify and refine their navigation objectives explicitly, and 3) support
                            the seven interaction intents.</span>
                        <span class="lessbutton" id="article3_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #HowtoVideos; #VoiceUserInterfaces #VideoInteraction </div>-->
                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://minsukchang.com/proj-voicevideo"> website </a> <a
                            class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://minsukchang.com/proj-voicevideo/CHI2019_Minsuk_VV_Adobe_CameraReady(8).pdf">
                            pdf </a>
                    </div>
                </div>


                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2018 </div>
                        <div class="title"> RecipeScape: An Interactive Tool for Analyzing Cooking Instructions at Scale
                        </div>
                        <div class="authors"> <span class="authorminsuk"> Minsuk Chang</span>, Leonore V. Guillain, <a
                                href="https://hyeungshikjung.com/">Hyeungshik Jung</a>, Vivian M. Hare, <a
                                href="https://juhokim.com">Juho Kim</a>, <a
                                href="https://graphics.stanford.edu/~maneesh/">Maneesh Agrawala </a></div>
                    </div>

                    <div class="abstract">
                        <!-- what to show first -->
                        For cooking professionals and culinary students, understanding cooking instructions is an
                        essential yet demanding task.
                        Common tasks include categorizing different approaches to cooking a dish and identifying usage
                        patterns of particular ingredients or cooking methods,
                        all of which require extensive browsing and comparison. However, no existing system provides
                        support for such in-depth and at-scale analysis.
                        <span class="morebutton" id="article2"> Read More </span>
                        <span class="readmore" id="article2_content">
                            <!-- rest of what to show on "more" -->
                            We present RecipeScape, an interactive system for browsing and analyzing the hundreds of
                            recipes of a single dish available online.
                            We also introduce a computational pipeline that extracts cooking processes from recipe text
                            and calculates a procedural similarity between them.
                            To evaluate how RecipeScape supports culinary analysis at scale,
                            we conducted a user study with cooking professionals and culinary students with 500 recipes
                            for two different dishes.
                            Results show that RecipeScape clusters recipes into distinct approaches, and captures
                            notable usage patterns of ingredients and cooking actions.
                        </span>
                        <span class="lessbutton" id="article2_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> <b>Keywords: </b>#InteractiveDataMining; #NaturallyCrowdsourcedData #ComputationalModels </div>-->
                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://recipescape.kixlab.org/"> website </a> <a
                            class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://recipescape.kixlab.org/RecipeScape_CHI_2018__Camera_Ready_.pdf"> pdf </a>
                    </div>
                </div>
            </div> <!-- right col md 8 end -->

            <div class="col-md-2"> </div>
        </div>
        <!-- pubs row end-->

        <!-- LBW row -->
        <div id="posters" class="row">

            <div class="col-md-2"> </div>
            <div class="col-md-8">
                <div class="pub">Posters, Demos, Workshop Papers</div>
                <!-- publication template 
                    <div class="eachpub">
                        <div class="meta">
                            <div class="conference"> </div>
                            <div class="title"> </div>
                            <div class="authors"> <b>Minsuk Chang</b> </div>
                        </div>
                        <div class="abstract">
                            
                            <span class="morebutton" id="article2"> Read More </span>
                            <span class="readmore" id="article2_content">
                            
                        
                            </span> 
                            <span class="lessbutton" id="article2_less"> Read Less </span>
                        </div>
                        <div class="links"> <a target="_blank" href=""> website </a>  &middot; <a target="_blank" href=""> pdf </a>
                        </div>
                    </div>
                -->
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> UIST 2019 Doctoral Symposium</div>
                        <div class="title"> Data Structures for Designing Interactions with Contextual Task Support
                        </div>
                        <div class="authors"> <span class="authorminsuk">Minsuk Chang</span></div>
                    </div>
                    <div class="abstract">

                        The diversity and the scale of available online instructions introduce opportunities but also
                        user challenges in currently used software interfaces;
                        Users have limited computational resources, and thus often make strategic decisions when
                        browsing, navigating, and understanding instructions to accomplish a task.
                        These strategic user interactions possess nuanced semantics such as users' interpretations,
                        intents, and contexts in which the task is carried out.

                        <span class="morebutton" id="article5"> Read More </span>

                        <span class="readmore" id="article5_content">
                            My dissertation research introduces techniques in constructing data structures that capture
                            the diverse strategies users employ in which the collective nuanced semantics across
                            multiple strategies are preserved.
                            These computational representations are then used as building blocks for designing novel
                            interactions that allow users to effectively browse and navigate instructions, and provide
                            contextual task guidance.
                            Specifically, I investigate 1) structure of instructions for task analysis at scale, 2)
                            structure of collective user task demonstrations, and 3) structure of object uses in how-to
                            videos for tracking, guiding and searching task states.
                            My research demonstrates that the user-centered organization of information extracted from
                            interaction traces enables novel interfaces with contextual task support.
                        </span>
                        <span class="lessbutton" id="article5_less"> Read Less </span>
                    </div>

                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="files/UIST2019_DocSym_Minsuk (2).pdf"> pdf </a> </div>
                </div>
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2019 Computational Modeling in Human-Computer Interaction Workshop
                        </div>
                        <div class="title"> User Centered Graphical Models of Interaction </div>
                        <div class="authors"> <span class="authorminsuk">Minsuk Chang</span>, <a
                                href="https://juhokim.com">Juho Kim</a></div>
                    </div>
                    <div class="abstract">

                        In this position paper, I present a set of data-driven techniques in modeling the learning
                        material,
                        learner workflow and the learning task as graphical representations,
                        with which at scale can create and support learning opportunities in the wild.
                        I propose the graphical models resulting from this bottom-up approach can further serve as
                        proxies for representing
                        learnability bounds of an interface.
                        <span class="morebutton" id="article5"> Read More </span>

                        <span class="readmore" id="article5_content">
                            I also propose an alternative approach which directly aims to "learn" the interaction bounds
                            by
                            modeling the interface as an agent's sequential decision making problem.
                            Then I illustrate how the data-driven modeling techniques and algorithm modeling techniques
                            can
                            create a mutually beneficial bridge for advancing design of interfaces.
                        </span>
                        <span class="lessbutton" id="article5_less"> Read Less </span>
                    </div>

                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://hcicompmodeling.wordpress.com/"> workshop website </a> <a
                            class="btn btn-outline-primary btn-sm disabled" target="_blank" href=""> pdf </a>
                        (Camera-ready will be available soon)</div>
                </div>
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2019 LBW </div>
                        <div class="title"> SolveDeep: A System for Supporting Subgoal Learning in Online Math Problem
                            Solving </div>
                        <div class="authors">Hyoungwook Jin, <span class="authorminsuk">Minsuk Chang</span>, <a
                                href="https://juhokim.com">Juho Kim</a></div>
                    </div>
                    <div class="abstract">
                        <!-- what to show first -->
                        Learner-driven subgoal labeling helps learners form a hierarchical structure of solutions with
                        subgoals,
                        which are conceptual units of procedural problem solving.
                        While learning with such hierarchical structure of a solution in mind is effective in learning
                        problem solving strategies,
                        the development of an interactive feedback system to support subgoal labeling tasks at scale
                        requires significant expert efforts,
                        making learner-driven subgoal labeling difficult to be applied in online learning environments.
                        We propose SolveDeep,
                        a system that provides feedback on learner solutions with peer-generated subgoals.
                        <span class="morebutton" id="article4"> Read More </span>
                        <span class="readmore" id="article4_content">
                            <!-- rest of what to show on "more" -->
                            SolveDeep utilizes a learnersourcing workflow to generate the hierarchical representation of
                            possible solutions,
                            and uses a graph-alignment algorithm to generate a solution graph by merging the populated
                            solution structures,
                            which are then used to generate feedback on future learners' solutions.
                            We conducted a user study with 7 participants to evaluate the efficacy of our system.
                            Participants did subgoal learning with two math problems and rated the usefulness of system
                            feedback.
                            The average rating was 4.86 out of 7 (1: Not useful, 7: Useful),
                            and the system could successfully construct a hierarchical structure of solutions with
                            learnersourced subgoal labels.
                        </span>
                        <span class="lessbutton" id="article4_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #Learnersourcing; #SubgoalLearning; #ComputationalModels </div>-->
                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="files/chi19c-sub1497-cam-i15.pdf"> pdf </a></div>
                </div>

                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2018 Sensemaking Workshop</div>
                        <div class="title"> Sensemaking around How-to-cook Videos</div>
                        <div class="authors"> <span class="authorminsuk">Minsuk Chang</span>, Seayeon Lee, <a
                                href="https://kyungjejo.com/"> Kyungje Jo</a>, <a href="https://juhokim.com">Juho
                                Kim</a> </div>
                    </div>
                    <div class="abstract">
                        We conducted a series of exploratory studies on sensemaking behaviors people exhibit while
                        watching how-to-cook
                        videos. The three different scenarios we examined are a) when people seek for alternatives in
                        ingredients, tools and
                        actions, b) when people seek for explanations or more detail on certain instructions, and c)
                        when people use text
                        search and when people use video when learning how to cook a dish.
                        <span class="morebutton" id="article0"> Read More </span>
                        <span class="readmore" id="article0_content">
                            We found a) people often make arbitrary decisions on substituting ingredients, cooking
                            tools, or cooking
                            actions while following instructions, b) people satisfice by verifying knowledge with little
                            data and not wanting to deviate
                            from the initially chosen video, and c) people use text search for definitions and
                            confirmation of substitutions while
                            they use video search for explanations and precise details for instruction steps
                        </span>
                        <span class="lessbutton" id="article0_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #HowtoVideos; #Sensemaking; #VideoInteraction  </div>-->
                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://sensemakingchi2018.com/"> workshop website </a> <a
                            class="btn btn-outline-primary btn-sm" target="_blank" href="files/Chang-SensemakingCookingVideos.pdf"> pdf </a>
                    </div>
                </div>

                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2017 LBW </div>
                        <div class="title">RecipeScape: Mining and Analyzing Diverse Processes in Cooking Recipes</div>
                        <div class="authors"> <span class="authorminsuk"> Minsuk Chang</span>, Vivian M. Hare, <a
                                href="https://juhokim.com">Juho Kim</a>, <a
                                href="https://graphics.stanford.edu/~maneesh/">Maneesh Agrawala </a></div>
                    </div>
                    <div class="abstract">
                        In culture analytics, it is important to ask fundamental questions that address salient
                        characteristics of collective human behavior.
                        This paper explores how analyzing cooking recipes in aggregate and at scale identifies these
                        characteristics in the cooking culture, and answer
                        fundamental questions like ”what makes a chocolate chip cookie a chocolate chip cookie?”.
                        <span class="morebutton" id="article1"> Read More </span>
                        <span class="readmore" id="article1_content">
                            Aspiring cooks, professional chefs and cooking hobbyists share their recipes online
                            resulting in thousands of different procedural instructions towards a shared goal. However,
                            existing approaches
                            focus merely on analysis at the ingredient level, for example, extracting ingredient
                            information from individual
                            recipes. We introduce RecipeScape, a prototype interface which supports visually querying,
                            browsing and comparing cooking recipes at scale. We also present the underlying
                            computational pipeline of RecipeScape that scrapes recipes online, extracts their ingredient
                            and instruction information, constructs a graphical representation, and computes similarity
                            between pairs of recipes.
                        </span>
                        <span class="lessbutton" id="article1_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #InteractiveDataMining; #NaturallyCrowdsourcedData #ComputationalModels </div>-->
                    <div class="links"> <a class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://recipescape.kixlab.org/"> website</a> <a
                            class="btn btn-outline-primary btn-sm" target="_blank"
                            href="https://recipescape.kixlab.org/ea1524-chang.pdf"> pdf </a>
                    </div>
                </div>
            </div>
            <div class="col-md-2"> </div>
        </div>
        <!-- news row end-->

        <!-- TMI row -->
        <div class="row">
            <div class="col-md-2"> </div>
            <div class="col-md-3">
                <div class="pub">Services</div>
                <div class="eachpub">
                    <div class="conference">Organizing Committee</div>
                    <!-- <div class="venue">SIGCHI Operations Committee</div> -->
                    <div class="venue">CHI 2021 Video Capture Co-Chair</div>
                    <div class="venue">ISS 2019 Video Chair</div>
                    <!-- <div class="venue">CHI 2021 Video Chair</div> -->
                </div>

                <div class="eachpub">
                    <div class="conference">Program Committee</div>
                    <div class="venue">GI 2020</div>
		    <div class="venue">WWW 2020</div>
                    <div class="venue">CHI 2019 LBW</div>
                </div>
                <div class="eachpub">
                    <div class="conference">Reviewer</div>
                    <div class="venue">CHI 2017, 2018, 2019, 2020</div>
                    <div class="venue">CSCW 2018, 2019, 2020 (Outstanding Review)</div>
                    <div class="venue">UIST 2017, 2018, 2020</div>
                    <div class="venue">MobileHCI 2019</div>
                </div>
                <div class="eachpub">
                    <div class="conference">Student Volunteer</div>
                    <div class="venue">CHI 2017</div>
                    <div class="venue">UIST 2017, 2018</div>
                </div>
            </div>
            <div class="col-md-5">
                <div class="pub">In the past,</div>
                <div class="abstract">
                    <p>
                        I studied Computer Science, Financial Engineering from KAIST, Finance from Simon Business School
                        @ University of Rochester,
                        and Statistics from Rutgers University. I have worked at an Hedge Fund in NYC trying to beat the
                        market by relentlessly
                        crunching numbers prior to coming (back) to KAIST.
                        I've spent two years in the reinforcement learning (as a subfield of machine learning) research
                        group at KAIST
                        as a Ph.D student before joining KIXLAB (the KAIST Interaction Lab).
                    </p>
                    <p>
                        I taught lab sessions for the mandatory Introduction to Programming course at KAIST from
                        2015-2018 as a Head TA.
                        I enjoyed working with 40 TAs and interacting with 450-500 students each semester.
                    </p>

                </div>
            </div>
            <div class="col-md-2"> </div>
        </div>

        <div class="row">
            <div class="col-md-2"> </div>
            <div class="col-md-8"> </div>
            <div class="col-md-2"> </div>
        </div>
    </div>




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
    <!-- Include Google Analytics Here-->
    <script>
        (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-77549813-1', 'auto');
        ga('send', 'pageview');
    </script>
</body>

</html>
